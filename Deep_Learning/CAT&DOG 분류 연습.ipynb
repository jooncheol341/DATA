{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "18634fe5",
   "metadata": {},
   "source": [
    "## 모듈 불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c23f5468",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd \n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import os\n",
    "import glob\n",
    "import tensorflow as tf\n",
    "import cv2\n",
    "from PIL import Image\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9f1ae8f",
   "metadata": {},
   "source": [
    "## 이미지를 불러오기 위한 준비"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5e6cc527",
   "metadata": {},
   "outputs": [],
   "source": [
    "filenames = os.listdir(\"D:/cat&dog\")\n",
    "categories = []\n",
    "for filename in filenames:\n",
    "    category = filename.split('.')[0]\n",
    "    if category == 'dog':\n",
    "        categories.append(1)\n",
    "    else:\n",
    "        categories.append(0)\n",
    "\n",
    "df = pd.DataFrame({\n",
    "    'filename': filenames,\n",
    "    'category': categories\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b05f68f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>cat.0.jpg</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>cat.1.jpg</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>cat.10.jpg</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>cat.100.jpg</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>cat.1000.jpg</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       filename  category\n",
       "0     cat.0.jpg         0\n",
       "1     cat.1.jpg         0\n",
       "2    cat.10.jpg         0\n",
       "3   cat.100.jpg         0\n",
       "4  cat.1000.jpg         0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c8e0dd2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 50000 entries, 0 to 49999\n",
      "Data columns (total 2 columns):\n",
      " #   Column    Non-Null Count  Dtype \n",
      "---  ------    --------------  ----- \n",
      " 0   filename  50000 non-null  object\n",
      " 1   category  50000 non-null  int64 \n",
      "dtypes: int64(1), object(1)\n",
      "memory usage: 781.4+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info() # 데이터셋의 정보를 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a99283b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    25000\n",
       "1    25000\n",
       "Name: category, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['category'].value_counts() # 분류하고자하는 클래스의 비율을 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "25ddf410",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: >"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df['category'].value_counts().plot.bar() # 시각화를 통해 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e8353698",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"category\"] = df[\"category\"].replace({0: 'cat', 1: 'dog'}) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6410c9f7",
   "metadata": {},
   "source": [
    "## 이미지 파일의 크기가 달라서 같은 크기 및 비율로 맞춰주기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c9ca95c",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_path = 'D:/cat&dog/*.jpg'\n",
    "file_list = [file for file in glob.glob(input_path)]\n",
    "\n",
    "\n",
    "img_resize_list = []\n",
    "for f in tqdm(file_list):\n",
    "    img = Image.open(f)\n",
    "    img_resize = img.resize((256, 256))\n",
    "    img_resize_list.append(img_resize.size)\n",
    "    \n",
    "    title, ext = os.path.splitext(f)\n",
    "    img_resize.save(title + '_resize' + ext)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24462f5c",
   "metadata": {},
   "source": [
    "# feature와 label 추출하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "353a5fe1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████| 25000/25000 [18:24<00:00, 22.64it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████| 25000/25000 [00:00<00:00, 183525.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(25000, 256, 256, 3) (25000,)\n"
     ]
    }
   ],
   "source": [
    "paths = glob.glob('D:/cat&dog/*_resize.jpg')\n",
    "paths = np.random.permutation(paths)\n",
    "paths[0]\n",
    "features = np.array([plt.imread(paths[i]) for i in tqdm(range(len(paths)))])\n",
    "label = np.array([paths[i].split('\\\\')[1].split('.')[0] for i in tqdm(range(len(paths)))])\n",
    "print(features.shape, label.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "552fbcdc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(25000, 256, 256, 3) (25000, 2)\n"
     ]
    }
   ],
   "source": [
    "label = pd.get_dummies(label)\n",
    "print(features.shape, label.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cd30d01",
   "metadata": {},
   "source": [
    "# 모델 만들기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "df712c09",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = tf.keras.layers.Input(shape = [256, 256, 3])\n",
    "\n",
    "H = tf.keras.layers.Conv2D(6, kernel_size = 5, activation = 'swish')(X)\n",
    "H = tf.keras.layers.MaxPool2D()(H)\n",
    "\n",
    "H = tf.keras.layers.Conv2D(6, kernel_size = 5, activation = 'swish')(H)\n",
    "H = tf.keras.layers.MaxPool2D()(H)\n",
    "\n",
    "H = tf.keras.layers.Flatten()(H)\n",
    "H = tf.keras.layers.Dense(120, activation = 'swish')(H)\n",
    "H = tf.keras.layers.Dense(84, activation = 'swish')(H)\n",
    "Y = tf.keras.layers.Dense(2, activation = 'softmax')(H)\n",
    "\n",
    "model = tf.keras.models.Model(X, Y)\n",
    "model.compile(loss = 'categorical_crossentropy', metrics = 'accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "64ef1706",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_3\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_4 (InputLayer)        [(None, 256, 256, 3)]     0         \n",
      "                                                                 \n",
      " conv2d_6 (Conv2D)           (None, 252, 252, 6)       456       \n",
      "                                                                 \n",
      " max_pooling2d_6 (MaxPooling  (None, 126, 126, 6)      0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_7 (Conv2D)           (None, 122, 122, 6)       906       \n",
      "                                                                 \n",
      " max_pooling2d_7 (MaxPooling  (None, 61, 61, 6)        0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " flatten_3 (Flatten)         (None, 22326)             0         \n",
      "                                                                 \n",
      " dense_9 (Dense)             (None, 120)               2679240   \n",
      "                                                                 \n",
      " dense_10 (Dense)            (None, 84)                10164     \n",
      "                                                                 \n",
      " dense_11 (Dense)            (None, 2)                 170       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2,690,936\n",
      "Trainable params: 2,690,936\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90b9931e",
   "metadata": {},
   "source": [
    "# 모델 학습하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "fd3cd232",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "782/782 [==============================] - 579s 740ms/step - loss: 5.4912 - accuracy: 0.5067\n",
      "Epoch 2/10\n",
      "782/782 [==============================] - 573s 733ms/step - loss: 0.7196 - accuracy: 0.5318\n",
      "Epoch 3/10\n",
      "782/782 [==============================] - 575s 735ms/step - loss: 0.7719 - accuracy: 0.5835\n",
      "Epoch 4/10\n",
      "782/782 [==============================] - 581s 743ms/step - loss: 0.7054 - accuracy: 0.6142\n",
      "Epoch 5/10\n",
      "782/782 [==============================] - 573s 733ms/step - loss: 0.6777 - accuracy: 0.6635\n",
      "Epoch 6/10\n",
      "782/782 [==============================] - 573s 733ms/step - loss: 0.5380 - accuracy: 0.7118\n",
      "Epoch 7/10\n",
      "782/782 [==============================] - 570s 729ms/step - loss: 0.4566 - accuracy: 0.7620\n",
      "Epoch 8/10\n",
      "782/782 [==============================] - 570s 729ms/step - loss: 0.5643 - accuracy: 0.8046\n",
      "Epoch 9/10\n",
      "782/782 [==============================] - 604s 773ms/step - loss: 0.3194 - accuracy: 0.8483\n",
      "Epoch 10/10\n",
      "782/782 [==============================] - 581s 743ms/step - loss: 0.2688 - accuracy: 0.8776\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2630b38b970>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(features, label, epochs = 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8e2fc37",
   "metadata": {},
   "source": [
    "# 모델로 예측 결과 확인하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "fe24a85f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 1s/step\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.84</td>\n",
       "      <td>0.16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.14</td>\n",
       "      <td>0.86</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.62</td>\n",
       "      <td>0.38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      0     1\n",
       "0  0.84  0.16\n",
       "1  1.00  0.00\n",
       "2  0.14  0.86\n",
       "3  0.62  0.38\n",
       "4  1.00  0.00"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred = model.predict(features[0:5])\n",
    "pd.DataFrame(pred).round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "54aff213",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cat</th>\n",
       "      <th>dog</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   cat  dog\n",
       "0    1    0\n",
       "1    1    0\n",
       "2    0    1\n",
       "3    1    0\n",
       "4    1    0"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "cf362df7",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mDownloading and preparing dataset Unknown size (download: Unknown size, generated: Unknown size, total: Unknown size) to C:\\Users\\chlwn\\tensorflow_datasets\\cats_vs_dogs\\4.0.0...\u001b[0m\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "421a49b801b9480ca29a18e888c9d6b2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Dl Completed...: 0 url [00:00, ? url/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "838780a60a3f492085ad2afdebc093dc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Dl Size...: 0 MiB [00:00, ? MiB/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating splits...:   0%|          | 0/1 [00:00<?, ? splits/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train examples...: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:1738 images were corrupted and were skipped\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Shuffling C:\\Users\\chlwn\\tensorflow_datasets\\cats_vs_dogs\\4.0.0.incompleteY0MKZF\\cats_vs_dogs-train.tfrecord*.…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mDataset cats_vs_dogs downloaded and prepared to C:\\Users\\chlwn\\tensorflow_datasets\\cats_vs_dogs\\4.0.0. Subsequent calls will reuse this data.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# import tensorflow_datasets as tfds\n",
    "\n",
    "# (raw_train, raw_validation, raw_test), metadata = tfds.load(\n",
    "#     'cats_vs_dogs',\n",
    "#     split=['train[:80%]','train[80%:90%]','train[90%:]'],\n",
    "#     with_info=True,\n",
    "#     as_supervised=True\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afb1b03a",
   "metadata": {},
   "source": [
    "# 모델 저장하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "e5c465fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('my_model.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fb24167",
   "metadata": {},
   "source": [
    "# 모델 불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "4d1709f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_3\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_4 (InputLayer)        [(None, 256, 256, 3)]     0         \n",
      "                                                                 \n",
      " conv2d_6 (Conv2D)           (None, 252, 252, 6)       456       \n",
      "                                                                 \n",
      " max_pooling2d_6 (MaxPooling  (None, 126, 126, 6)      0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_7 (Conv2D)           (None, 122, 122, 6)       906       \n",
      "                                                                 \n",
      " max_pooling2d_7 (MaxPooling  (None, 61, 61, 6)        0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " flatten_3 (Flatten)         (None, 22326)             0         \n",
      "                                                                 \n",
      " dense_9 (Dense)             (None, 120)               2679240   \n",
      "                                                                 \n",
      " dense_10 (Dense)            (None, 84)                10164     \n",
      "                                                                 \n",
      " dense_11 (Dense)            (None, 2)                 170       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2,690,936\n",
      "Trainable params: 2,690,936\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from tensorflow import keras\n",
    "\n",
    "new_model = keras.models.load_model('my_model.h5')\n",
    "# Show the model architecture\n",
    "new_model.summary()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
